{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ba4ad98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\perpendicooler\\anaconda3\\lib\\site-packages (2.0.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\perpendicooler\\anaconda3\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\perpendicooler\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\perpendicooler\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\perpendicooler\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\perpendicooler\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\perpendicooler\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\perpendicooler\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\perpendicooler\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\perpendicooler\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas scikit-learn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48763d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "The data parser file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "93078cb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 140807 entries in the file overall.\n",
      "There are 69390 entries for towns in Europe.\n",
      "The distance between Cerreto Castello and Saint-Melaine-sur-Aubance is 692.2505607394098 km.\n",
      "There are 2872 entries for towns in Poland.\n",
      "The distance between Żurowa and Wyśmierzyce is 201.5473452215105 km.\n"
     ]
    }
   ],
   "source": [
    "# /usr/bin/env python3\n",
    "import itertools\n",
    "import pandas\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from math import radians\n",
    "\n",
    "\n",
    "def distance(row1, row2):\n",
    "    \"\"\"Computes the Haversine distance between two towns in the database.\n",
    "    Source: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.haversine_distances.html\"\"\"\n",
    "    pos1 = (row1['coordinates']['lat'], row1['coordinates']['lon'])\n",
    "    pos2 = (row2['coordinates']['lat'], row2['coordinates']['lon'])\n",
    "    radians1 = [radians(pos1[0]), radians(pos1[1])]\n",
    "    radians2 = [radians(pos2[0]), radians(pos2[1])]\n",
    "    res = haversine_distances([radians1, radians2])\n",
    "    res *= 6371000 / 1000  # multiply by Earth radius to get kilometers\n",
    "    return res[0][1]\n",
    "\n",
    "\n",
    "# The following is a simple example of parsing the dataset. You are free to extract any subset of the cities\n",
    "# to benchmark your LP/ILP solutions. You can also transform the dataset into some intermediary data that is\n",
    "# easier to parse -- for example, creating the distance matrix explicitly, and not just implicitly.\n",
    "\n",
    "# You are also free to implement the solution in a language other than Python. In that case, please use the same\n",
    "# dataset, so that the results are somewhat comparable.\n",
    "\n",
    "# Data source: https://public.opendatasoft.com/explore/dataset/geonames-all-cities-with-a-population-1000/information/?disjunctive.cou_name_en&sort=name\n",
    "\n",
    "df = pandas.read_json(\"dataset.json\")\n",
    "print(f\"There are {len(df.index)} entries in the file overall.\")\n",
    "europe = df[df['timezone'].str.contains(\"Europe\")]\n",
    "print(f\"There are {len(europe.index)} entries for towns in Europe.\")\n",
    "first_in_europe = europe.iloc[0]\n",
    "second_in_europe = europe.iloc[-1]\n",
    "print(f\"The distance between {first_in_europe['name']} and {second_in_europe['name']} is \"\n",
    "      f\"{distance(first_in_europe, second_in_europe)} km.\")\n",
    "\n",
    "poland = europe[europe['country_code'].str.contains('PL')]\n",
    "print(f\"There are {len(poland.index)} entries for towns in Poland.\")\n",
    "first_in_poland = poland.iloc[0]\n",
    "second_in_poland = poland.iloc[1]\n",
    "\n",
    "print(f\"The distance between {first_in_poland['name']} and {second_in_poland['name']} is \"\n",
    "      f\"{distance(first_in_poland, second_in_poland)} km.\")\n",
    "\n",
    "# The actual distance between Żurowa and Wyśmierzyce seems to be 219 kms, and the function claims 201 km.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af1e82",
   "metadata": {},
   "source": [
    "# To find the Pair wise distance between any city We have sorted the poland's cities only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "818579de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from math import radians\n",
    "\n",
    "def distance(row1, row2):\n",
    "    pos1 = (row1['coordinates']['lat'], row1['coordinates']['lon'])\n",
    "    pos2 = (row2['coordinates']['lat'], row2['coordinates']['lon'])\n",
    "    radians1 = [radians(pos1[0]), radians(pos1[1])]\n",
    "    radians2 = [radians(pos2[0]), radians(pos2[1])]\n",
    "    res = haversine_distances([radians1, radians2])\n",
    "    res *= 6371000 / 1000  # multiply by Earth radius to get kilometers\n",
    "    return res[0][1]\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_json(\"dataset.json\")\n",
    "\n",
    "# Extract relevant columns for the first 500 cities in Poland\n",
    "poland_data = df[df['country_code'] == 'PL'].head(500)[['name', 'coordinates']]\n",
    "\n",
    "# Initialize an empty list to store pairs of cities and distances\n",
    "distances = []\n",
    "\n",
    "# Iterate through each pair of cities in the first 50 cities in Poland\n",
    "for (city1_idx, city1), (city2_idx, city2) in itertools.combinations(poland_data.iterrows(), 2):\n",
    "    dist = distance(city1, city2)\n",
    "    \n",
    "    # Append the pair and distance to the list\n",
    "    distances.append((city1['name'], city2['name'], dist))\n",
    "\n",
    "# Create a dataframe from the distances\n",
    "distance_df = pd.DataFrame(distances, columns=['From', 'To', 'Distance'])\n",
    "\n",
    "# Store the distances in an Excel file\n",
    "distance_df.to_excel('poland_500_cities_pairwise_distances.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d2e462",
   "metadata": {},
   "source": [
    "the distance from Żurowa to all other cities in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2cc7eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# /usr/bin/env python3\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from math import radians\n",
    "import itertools\n",
    "\n",
    "def distance(row1, row2):\n",
    "    # Computes the Haversine distance between two towns in the database\n",
    "    pos1 = (row1['coordinates']['lat'], row1['coordinates']['lon'])\n",
    "    pos2 = (row2['coordinates']['lat'], row2['coordinates']['lon'])\n",
    "    radians1 = [radians(pos1[0]), radians(pos1[1])]\n",
    "    radians2 = [radians(pos2[0]), radians(pos2[1])]\n",
    "    res = haversine_distances([radians1, radians2])\n",
    "    res *= 6371000 / 1000  # multiply by Earth radius to get kilometers\n",
    "    return res[0][1]\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_json(\"dataset.json\")\n",
    "\n",
    "# Select the city of Żurowa\n",
    "zurowa = df[df['name'] == 'Żurowa']\n",
    "poland = df[df['country_code'] == 'PL']\n",
    "\n",
    "# Calculate the distance from Żurowa to all other cities in the dataset\n",
    "distances = []\n",
    "for index, row in poland.iterrows():\n",
    "    dist = distance(zurowa.iloc[0], row)\n",
    "    distances.append((zurowa['name'].values[0], row['name'], dist))\n",
    "\n",
    "# Create a dataframe from the distances\n",
    "distance_df = pd.DataFrame(distances, columns=['From', 'To', 'Distance'])\n",
    "\n",
    "# Store the distances in an Excel file\n",
    "distance_df.to_excel('zurowa_distances.xlsx', index=False)\n",
    "\n",
    "# Create a subset of 500 cities\n",
    "subset = distance_df.nsmallest(500, 'Distance')\n",
    "\n",
    "# Store the subset in an Excel file\n",
    "subset.to_excel('zurowa_distances_to_polish_cities_subset.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e244d73",
   "metadata": {},
   "source": [
    "If this one execute the output will show each pairwise_distances.xlsx, all of the citie in dataset.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27cf5243",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'lat'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lat'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Iterate through each pair of cities\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (city1, coord1), (city2, coord2) \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mcombinations(city_data\u001b[38;5;241m.\u001b[39miterrows(), \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m---> 23\u001b[0m     dist \u001b[38;5;241m=\u001b[39m haversine_distance((coord1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m], coord1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m]), (coord2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlat\u001b[39m\u001b[38;5;124m'\u001b[39m], coord2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlon\u001b[39m\u001b[38;5;124m'\u001b[39m]))\n\u001b[0;32m     25\u001b[0m     \u001b[38;5;66;03m# Append the pair and distance to the list\u001b[39;00m\n\u001b[0;32m     26\u001b[0m     distances\u001b[38;5;241m.\u001b[39mappend((city1, city2, dist))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1007\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1004\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1006\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1007\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m   1009\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_hashable(key):\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;66;03m# Otherwise index.get_value will raise InvalidIndexError\u001b[39;00m\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1012\u001b[0m         \u001b[38;5;66;03m# For labels that don't resolve as scalars like tuples and frozensets\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1116\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1115\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1116\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lat'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from math import radians\n",
    "\n",
    "def haversine_distance(pos1, pos2):\n",
    "    radians1 = [radians(pos1[0]), radians(pos1[1])]\n",
    "    radians2 = [radians(pos2[0]), radians(pos2[1])]\n",
    "    res = haversine_distances([radians1, radians2])\n",
    "    res *= 6371000 / 1000  # multiply by Earth radius to get kilometers\n",
    "    return res[0][1]\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_json(\"dataset.json\")\n",
    "\n",
    "# Extract relevant columns\n",
    "city_data = df[['name', 'coordinates']]\n",
    "\n",
    "# Initialize an empty list to store pairs of cities and distances\n",
    "distances = []\n",
    "\n",
    "# Iterate through each pair of cities\n",
    "for (city1, coord1), (city2, coord2) in itertools.combinations(city_data.iterrows(), 2):\n",
    "    dist = haversine_distance((coord1['lat'], coord1['lon']), (coord2['lat'], coord2['lon']))\n",
    "    \n",
    "    # Append the pair and distance to the list\n",
    "    distances.append((city1, city2, dist))\n",
    "\n",
    "# Create a dataframe from the distances\n",
    "distance_df = pd.DataFrame(distances, columns=['From', 'To', 'Distance'])\n",
    "\n",
    "# Store the distances in an Excel file\n",
    "distance_df.to_excel('pairwise_distances.xlsx', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
